[["index.html", "Exploring Thompsons Creek Stage Discharge Data About Data Import Data Explore IQPlus Site 16397 site 16882", " Exploring Thompsons Creek Stage Discharge Data 2021-02-11 About This document is an exploratory analysis of the pressure data and IQ data at … library(readr) library(tibble) library(dplyr) library(ggplot2) library(stringr) library(here) library(units) library(ggforce) library(hrbrthemes) library(lubridate) library(purrr) library(hydroGOF) update_geom_font_defaults(font_rc) theme_ms &lt;- function(...) { theme_ipsum_pub(plot_margin = margin(10,10,10,10), axis_title_just = &quot;c&quot;) + theme(legend.position = &quot;bottom&quot;, panel.background = element_rect(fill = &quot;white&quot;, colour = NA), panel.border = element_rect(fill = NA, colour = &quot;grey20&quot;), ...) } Data Import Pressure Transducers Use readr::read_csv() to import data. The HOBO pressure data is pre-computed but has extra lines we need to clean up. each location has two files, March through August and August through December. ideally, I can make one dataframe that compiles all the data we can read all the files and row bind but we need to add a column indicating the site number for this deployment it looks like the daylight savings time adjustment is not applied to data. So everything between March 6 and November 1 is off 1 hour from DST. Assuming all data will be reported in observed time, it is probably easiest to convert time back to GMT, then apply R’s built in time zones to convert the times with appropriate -5 or -6 hour offsets. ## make a list of files to import file_paths &lt;- paste0(here(&quot;Data/Hobo&quot;), &quot;/&quot;, list.files(path = here(&quot;Data/Hobo&quot;), pattern = &quot;.csv&quot;)) ## create a blank tibble to fill hobo_df &lt;- tibble() ## loop through file paths to read each file for (i in file_paths) { x &lt;- read_csv( i, skip = 2, col_names = c( &quot;Row&quot;, &quot;Date&quot;, &quot;Time&quot;, &quot;Abs_Pres&quot;, &quot;Temp&quot;, &quot;Bar_Pressure&quot;, &quot;Water_Level&quot;, &quot;Coupler_Detached&quot;, &quot;Coupler_Attached&quot;, &quot;Stopped&quot;, &quot;EOF&quot; ), col_types = &quot;nccnnnncccc&quot; ) x$file &lt;- i hobo_df &lt;- bind_rows(hobo_df, x) rm(x) } ## clean up the dataframe hobo_df &lt;- hobo_df %&gt;% mutate( ## regex extracts site number from file path Site = str_extract(file, &quot;\\\\d{1,6}&quot;), ## convert date and time columns to date/time format dt = paste(Date, Time), Date_Time = as.POSIXct(paste(Date, Time), tz = &quot;Etc/GMT-6&quot;, format = &quot;%m/%d/%y %I:%M:%S %p&quot;)) %&gt;% mutate(Site = as.factor(Site)) %&gt;% ## select the columns we need to keep dplyr::select(Abs_Pres, Temp, Water_Level, Site, Date_Time) %&gt;% ## filter rows without water_level dplyr::filter(!is.na(Water_Level)) ## attach units to our columns units(hobo_df$Water_Level) &lt;- as_units(&quot;ft&quot;) units(hobo_df$Temp) &lt;- as_units(&quot;°F&quot;) units(hobo_df$Abs_Pres) &lt;- as_units(&quot;psi&quot;) hobo_df ## # A tibble: 71,447 x 5 ## Abs_Pres Temp Water_Level Site Date_Time ## [psi] [°F] [ft] &lt;fct&gt; &lt;dttm&gt; ## 1 14.4270 76.006 0.392 16396 2020-03-02 15:17:19 ## 2 14.4237 75.659 0.388 16396 2020-03-02 15:32:19 ## 3 14.4272 75.312 0.399 16396 2020-03-02 15:47:19 ## 4 14.4192 74.964 0.391 16396 2020-03-02 16:02:19 ## 5 14.4165 74.791 0.379 16396 2020-03-02 16:17:19 ## 6 14.4153 74.446 0.361 16396 2020-03-02 16:32:19 ## 7 14.4172 74.271 0.364 16396 2020-03-02 16:47:19 ## 8 14.4166 74.098 0.363 16396 2020-03-02 17:02:19 ## 9 14.4207 73.926 0.372 16396 2020-03-02 17:17:19 ## 10 14.4270 73.753 0.376 16396 2020-03-02 17:32:19 ## # … with 71,437 more rows IQ Plus #read_csv(here::here(&quot;Data/IQPlus/16397-2020_12_31.csv&quot;)) ## make a list of files to import file_paths &lt;- paste0(here(&quot;Data/IQPlus&quot;), &quot;/&quot;, list.files(path = here(&quot;Data/IQPlus&quot;), pattern = &quot;.csv&quot;)) ## create a blank tibble to fill iqplus_df &lt;- tibble() ## loop through file paths to read each file for (i in file_paths) { x &lt;- read_csv( i, col_types = &quot;nc______n__n______________________nn______n_________&quot; ) x$file &lt;- i iqplus_df &lt;- bind_rows(iqplus_df, x) rm(x) } iqplus_df &lt;- iqplus_df %&gt;% mutate( ## regex extracts site number from file path Site = str_extract(file, &quot;\\\\d{1,6}&quot;)) %&gt;% ## use `dplyr::` to specify which rename function to use, just in case dplyr::rename(Sample_Number =`Sample number`, Date_Time = `Sample time`, Depth = `Depth (ft)`, Flow = `Flow (ft³/s)`, System_In_Water = `System in water (%)`, System_Status = `System status (status codes)`, Index_Velocity = `Velocity (mean) (ft/s)`) %&gt;% dplyr::select(-c(Sample_Number, file)) %&gt;% mutate(Date_Time = as.POSIXct(Date_Time, tz = &quot;Etc/GMT-6&quot;, format = &quot;%Y-%m-%d %H:%M:%S&quot;)) ## attach units to our columns units(iqplus_df$Depth) &lt;- as_units(&quot;ft&quot;) units(iqplus_df$Flow) &lt;- as_units(&quot;ft^3/s&quot;) units(iqplus_df$Index_Velocity) &lt;- as_units(&quot;ft/s&quot;) iqplus_df ## # A tibble: 41,625 x 7 ## Date_Time Depth Flow System_In_Water System_Status ## &lt;dttm&gt; [ft] [ft^3/s] &lt;dbl&gt; &lt;dbl&gt; ## 1 2020-05-12 16:58:00 1.758559 17.25626 100 0 ## 2 2020-05-12 17:13:00 1.867973 20.86921 100 0 ## 3 2020-05-12 17:28:00 2.006131 27.27231 100 0 ## 4 2020-05-12 17:43:00 2.119382 31.04828 100 0 ## 5 2020-05-12 17:58:00 2.172015 33.71041 100 0 ## 6 2020-05-12 18:13:00 2.228058 36.78339 100 0 ## 7 2020-05-12 18:28:00 2.350440 44.18084 100 0 ## 8 2020-05-12 18:43:00 2.508431 51.30917 100 0 ## 9 2020-05-12 18:58:00 2.674151 60.84247 100 0 ## 10 2020-05-12 19:13:00 2.809936 69.92496 100 0 ## # … with 41,615 more rows, and 2 more variables: Index_Velocity [ft/s], ## # Site &lt;chr&gt; Data Explore Pressure Transducers Plot the depth date over time for all three sites ## note, that if the scale name has a space, there is a bug in ggforce ## need to set units_options(parse = FALSE) per: ## https://github.com/thomasp85/ggforce/issues/197 ggplot(hobo_df) + geom_line(aes(Date_Time, Water_Level, color = Site)) + scale_y_unit(name = &quot;Level&quot;, unit = &quot;ft&quot;) + scale_x_datetime(name = &quot;Date/Time&quot;) + labs(title = &quot;15-Minute Measured Height&quot;) + theme_ms() IQPlus Plot the depth data drom the IQPlus from all three sites. iqplus_df %&gt;% filter(System_Status == 0, System_In_Water == 100) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth, color = Site)) + facet_wrap(~Site, scales = &quot;free&quot;) + labs(title = &quot;Stage&quot;) + theme_ms() Plot the depth-discharge from all three sites as measured by the IQPlus. iqplus_df %&gt;% filter(System_Status == 0, System_In_Water == 100, as.numeric(Flow) &gt; 0) %&gt;% ggplot() + geom_point(aes(Depth, Flow, color = Site)) + scale_y_unit(name = &quot;Flow&quot;, unit = &quot;ft^3/s&quot;) + facet_wrap(~Site, scales = &quot;free&quot;) + labs(title = &quot;Stage Discharge&quot;) + theme_ms() iqplus_df %&gt;% filter(System_Status == 0, System_In_Water == 100) %&gt;% mutate(Month = lubridate::month(Date_Time, label = TRUE)) %&gt;% ggplot() + geom_point(aes(Depth, Flow, color = Month), alpha = 0.5) + scale_y_unit(name = &quot;Flow&quot;, unit = &quot;ft^3/s&quot;) + facet_wrap(~Site, scales = &quot;free&quot;) + labs(title = &quot;Stage Discharge&quot;) + theme_ms() Site 16396 looks pretty good. We still have some data cleaning and sorting on the remaining two sites. Exploring 16397 further… iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, #as.numeric(Depth) &gt;= 0.75, as.numeric(Flow) &gt; 0) %&gt;% mutate(Month = lubridate::month(Date_Time, label = TRUE)) %&gt;% ggplot() + geom_point(aes(Depth, Flow, color = Month), alpha = 0.5) + scale_y_unit(name = &quot;Flow&quot;, unit = &quot;ft^3/s&quot;) + facet_wrap(~Month) + labs(title = &quot;Stage Discharge&quot;) + theme_ms() + theme(panel.spacing = unit(2, &quot;points&quot;)) Exploring 16882 further… iqplus_df %&gt;% filter(Site == &quot;16882&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Flow) &gt; 0) %&gt;% mutate(Month = lubridate::month(Date_Time, label = TRUE)) %&gt;% ggplot() + geom_point(aes(Depth, Flow, color = Month), alpha = 0.5) + scale_y_unit(name = &quot;Flow&quot;, unit = &quot;ft^3/s&quot;) + facet_wrap(~Month) + labs(title = &quot;Stage Discharge&quot;) + theme_ms() + theme(panel.spacing = unit(2, &quot;points&quot;)) The looped rating curve in May and Dec might be a flood flow event. Discharge is typically higher on the rising stage than the falling stage. iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &lt;= as.POSIXct(&quot;2020-07-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &lt;= as.POSIXct(&quot;2020-07-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &lt;= as.POSIXct(&quot;2020-07-01&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-07-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-09-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-07-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-09-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-07-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-09-01&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-09-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-10-15&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-09-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-10-15&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-09-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-10-15&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-10-15&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-11-25&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-10-15&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-11-25&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-10-15&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-11-25&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-11-25&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-15&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-11-25&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-15&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-11-25&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-15&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-12-15&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-12-15&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-12-15&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) ##16396 iqplus_df %&gt;% filter(Site == &quot;16396&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-12-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16396&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-12-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16396&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-12-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow, color = Date_Time)) + scale_y_unit(trans = &quot;log10&quot;) iqplus_df %&gt;% filter(Site == &quot;16396&quot;, #System_Status == 0, #System_In_Water == 100, #as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16396&quot;, #System_Status == 0, #System_In_Water == 100, #as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16396&quot;, #System_Status == 0, #System_In_Water == 100, #as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow, color = Date_Time)) The Jones Formula can be used to estimate the hysteresis or unstready flow depicted in the rating curve. A reduced formula described by Petersen-Øverleir (2006) and Zakwan (2018) is used here. \\[ Q = K(h-a)^n\\times\\sqrt{1 + x\\frac{\\partial h}{\\partial t}} \\] \\(Q\\) is discharge \\(h\\) is gage height \\(\\frac{\\partial h}{\\partial t}}\\) is the partial first order derivative approximated using finite differences. This can be considered the slope or instantaneous rate of change for the function between gage height and time which is estimated using measured stream height values. Solve for K, a, n, x by minimizing sum of square error (SSE). \\[ SSE = \\sum\\limits_{i=1}^N[X-Y]^2 \\] In order to incorporate the first derivative of stream height function we will need to (1) split the data set into each sampling period; (2) calculate the derivatives in each dataset; (3) remove rows with NA (basically first record in each sampling event); (4) combine desired datasets based on shape or sample the datasets; (4) refit the function above to one or more datasets. iqplus_df %&gt;% filter(Site == &quot;16396&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% arrange(Date_Time) %&gt;% mutate(time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;))) %&gt;% group_split(cumsum(diff_time &gt; 8)) %&gt;% ## remove events where max flow did not go over 10 cfs keep(~ max(as.numeric(.x$Flow)) &gt; 10) %&gt;% map(~select(.x, Date_Time, Depth, Flow)) %&gt;% map(~mutate(.x, time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;)), diff_depth = c(0, diff(.x$Depth)))) %&gt;% imap(~mutate(.x, event = as.character(.y))) %&gt;% bind_rows() %&gt;% filter(!is.na(diff_depth)) %&gt;% mutate(J = as.numeric(diff_depth)/as.numeric(diff_time)) -&gt; df_16396 exponent &lt;- function(x, pow) { (abs(x)^pow)*sign(x) } SSE &lt;- function(pars, data) { Depth = as.numeric(data$Depth) J = data$J K = pars[1] a = pars[2] n = pars[3] x = pars[4] preds &lt;- (K*exponent(x = Depth - a, pow = n)) * exponent(x = (1 + x * J), pow = (1/2)) #print(preds) Q = as.numeric(data$Flow) ## minimize the sum of square errors per the paper sse &lt;- sum((Q - preds)^2, na.rm = TRUE) #print(sse) sse } par &lt;- c(K = 5, a = 5, n = 2, x = 2000) ## limits to the parameter space lower &lt;- c(0.1, 0.1, 0.1, 0.1) upper &lt;- c(200, Inf, 10, 5000) optim.par &lt;- optim(par = par, fn = SSE, data = df_16396, lower = lower, upper = upper, method = &quot;L-BFGS-B&quot;) K &lt;- optim.par$par[[1]] a &lt;- optim.par$par[[2]] n &lt;- optim.par$par[[3]] x &lt;- optim.par$par[[4]] df_16396 %&gt;% mutate(predicted = (K*exponent(x = as.numeric(Depth) - a, pow = n)) * exponent(x = (1 + x * J), pow = (1/2))) %&gt;% ggplot() + geom_point(aes(as.numeric(Depth), as.numeric(Flow), color = &quot;measured&quot;), alpha = 0.5) + geom_point(aes(as.numeric(Depth), as.numeric(predicted), color = &quot;predicted&quot;), alpha = 0.2) + scale_y_log10() + theme_ms() ## Warning: Removed 8 rows containing missing values (geom_point). df_16396 %&gt;% mutate(predicted = (K*exponent(x = as.numeric(Depth) - a, pow = n)) * exponent(x = (1 + x * J), pow = (1/2))) %&gt;% ggplot() + geom_point(aes(as.numeric(Flow), as.numeric(predicted), color = &quot;measured&quot;), alpha = 0.5) + geom_abline(slope = 1) + scale_y_log10() + scale_x_log10() + theme_ms() ## Warning: Removed 8 rows containing missing values (geom_point). df_16396 %&gt;% mutate(predicted = (K*exponent(x = as.numeric(Depth) - a, pow = n)) * exponent(x = (1 + x * J), pow = (1/2))) -&gt; df_16396 df_16396_results &lt;- tibble(Site = &quot;16396&quot;, K = K, a = a, n = n, x = x, NSE = hydroGOF::NSE(df_16396$predicted, as.numeric(df_16396$Flow)), RMSE = hydroGOF::rmse(df_16396$predicted, as.numeric(df_16396$Flow))) df_16396_results ## # A tibble: 1 x 7 ## Site K a n x NSE RMSE ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 16396 29.8 1.02 1.60 0.507 0.978 11.4 Site 16397 This site was pooled from August through November 2020. It appears we can use the standard power function (Venetis 1970): \\[ Q = K(H-H_0)^z \\] iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt;= as.POSIXct(&quot;2020-12-15&quot;) &amp; Date_Time &gt;= as.POSIXct(&quot;2020-12-31&quot;) &amp; as.numeric(Depth) &gt; 1.5 | Date_Time &gt;= as.POSIXct(&quot;2020-01-05&quot;) &amp; as.numeric(Depth) &gt; 2) %&gt;% # filter(as.numeric(Depth) &lt; 2 &amp; as.numeric(Flow) &lt; 4.3 | # low flow outliers filtered based on boxplots # as.numeric(Depth) &gt;= 2) %&gt;% arrange(Date_Time) %&gt;% mutate(time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;))) %&gt;% group_split(cumsum(diff_time &gt; 8)) %&gt;% ## remove events where max flow did not go over 10 cfs ## keep(~ max(as.numeric(.x$Flow)) &gt; 10) %&gt;% map(~select(.x, Date_Time, Depth, Flow)) %&gt;% map(~mutate(.x, time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;)), diff_depth = c(0, diff(.x$Depth)))) %&gt;% imap(~mutate(.x, event = as.character(.y))) %&gt;% bind_rows() %&gt;% filter(!is.na(diff_depth)) %&gt;% mutate(J = as.numeric(diff_depth)/as.numeric(diff_time)) -&gt; df_16397 df_16397 %&gt;% filter(as.numeric(Depth) &lt; 2) %&gt;% ggplot() + geom_boxplot(aes(y = Flow)) # SSE &lt;- function(pars, data) { # Depth = as.numeric(data$Depth) # J = data$J # K = pars[1] # a = pars[2] # n = pars[3] # x = pars[4] # # # preds &lt;- (K*exponent(x = Depth - a, pow = n)) * exponent(x = (1 + x * J), pow = (1/2)) # #print(preds) # Q = as.numeric(data$Flow) # # ## minimize the sum of square errors per the paper # sse &lt;- sum((Q - preds)^2, na.rm = TRUE) # #print(sse) # sse # } # # par &lt;- c(K = 5, # a = 5, # n = 2, # x = 2000) # # ## limits to the parameter space # lower &lt;- c(0.1, 0.1, 0.1, 0.1) # upper &lt;- c(200, Inf, 10, 5000) # # optim.par &lt;- optim(par = par, # fn = SSE, # data = df_16397 %&gt;% filter(!is.infinite(J)), # lower = lower, # upper = upper, # method = &quot;L-BFGS-B&quot;) # # # K &lt;- optim.par$par[[1]] # a &lt;- optim.par$par[[2]] # n &lt;- optim.par$par[[3]] # x &lt;- optim.par$par[[4]] SSE &lt;- function(pars, data) { Depth = as.numeric(data$Depth) K = pars[1] H_0 = pars[2] Z = pars[3] preds &lt;- K*(as.numeric(Depth) - H_0)^Z #print(preds) Q = as.numeric(data$Flow) ## minimize the sum of square errors per the paper sse &lt;- sum((Q - preds)^2, na.rm = TRUE) #print(sse) sse } par &lt;- c(K = 1, H_0 = .001, Z = 2) ## limits to the parameter space lower &lt;- c(-Inf, -5, 0.001) upper &lt;- c(Inf, 5, Inf) optim.par &lt;- optim(par = par, fn = SSE, data = df_16397, lower = lower, upper = upper, method = &quot;L-BFGS-B&quot;) optim.par ## $par ## K H_0 Z ## 0.004524273 -2.870003103 4.148212545 ## ## $value ## [1] 302.7499 ## ## $counts ## function gradient ## 156 156 ## ## $convergence ## [1] 1 ## ## $message ## [1] &quot;NEW_X&quot; K &lt;- optim.par$par[[1]] H_0 &lt;- optim.par$par[[2]] Z &lt;- optim.par$par[[3]] df_16397 %&gt;% mutate(predicted = K*(as.numeric(Depth) - H_0)^Z) %&gt;% ggplot() + geom_point(aes(as.numeric(Depth), as.numeric(Flow), color = &quot;measured&quot;), alpha = 0.5) + geom_point(aes(as.numeric(Depth), as.numeric(predicted), color = &quot;predicted&quot;), alpha = 0.2) + scale_y_log10() + theme_ms() df_16397 %&gt;% mutate(predicted = K*(as.numeric(Depth) - H_0)^Z) %&gt;% ggplot() + geom_point(aes(as.numeric(Flow), as.numeric(predicted), color = &quot;measured&quot;), alpha = 0.5) + geom_abline(slope = 1) + #scale_y_log10() + scale_x_log10() + theme_ms() df_16397 %&gt;% mutate(predicted = K*(as.numeric(Depth) - H_0)^Z) -&gt; df_16397 df_16397_results &lt;- tibble(Site = &quot;16397&quot;, K = K, H_0 = H_0, Z = Z, NSE = hydroGOF::NSE(df_16397$predicted, as.numeric(df_16397$Flow)), RMSE = hydroGOF::rmse(df_16397$predicted, as.numeric(df_16397$Flow))) df_16397_results ## # A tibble: 1 x 6 ## Site K H_0 Z NSE RMSE ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 16397 0.00452 -2.87 4.15 0.969 2.13 site 16882 iqplus_df %&gt;% filter(Site == &quot;16882&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= .26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% ## remove outliers identified in box plots under 1 foot depth filter(as.numeric(Depth) &lt; 1 &amp; as.numeric(Flow) &lt; 4.3 | as.numeric(Depth) &gt; 1) %&gt;% arrange(Date_Time) %&gt;% mutate(time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;))) %&gt;% group_split(cumsum(diff_time &gt; 8)) %&gt;% ## remove events where max flow did not go over 10 cfs keep(~ max(as.numeric(.x$Flow)) &gt; 10) %&gt;% map(~select(.x, Date_Time, Depth, Flow)) %&gt;% map(~mutate(.x, time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;)), diff_depth = c(0, diff(.x$Depth)))) %&gt;% imap(~mutate(.x, event = as.character(.y))) %&gt;% bind_rows() %&gt;% filter(!is.na(diff_depth)) %&gt;% mutate(J = as.numeric(diff_depth)/as.numeric(diff_time)) -&gt; df_16882 df_16882 %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-11-01&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) df_16882 %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-05-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-06-01&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) df_16882 %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-10-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-11-01&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) SSE &lt;- function(pars, data) { Depth = as.numeric(data$Depth) J = data$J K = pars[1] a = pars[2] n = pars[3] x = pars[4] preds &lt;- (K*exponent(x = Depth - a, pow = n)) * exponent(x = (1 + x * J), pow = (1/2)) #print(preds) Q = as.numeric(data$Flow) ## minimize the sum of square errors per the paper sse &lt;- sum((Q - preds)^2, na.rm = TRUE) #print(sse) sse } par &lt;- c(K = 5, a = 5, n = 2, x = 5000) ## limits to the parameter space lower &lt;- c(0.1, 0.00001, 0.00001, -10) upper &lt;- c(200, 10, 10, 10) optim.par &lt;- optim(par = par, fn = SSE, data = df_16882 %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-05-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-06-01&quot;) &amp; !is.infinite(J) | Date_Time &gt; as.POSIXct(&quot;2020-10-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-11-01&quot;) &amp; !is.infinite(J)), lower = lower, upper = upper, method = &quot;L-BFGS-B&quot;) K &lt;- optim.par$par[[1]] a &lt;- optim.par$par[[2]] n &lt;- optim.par$par[[3]] x &lt;- optim.par$par[[4]] optim.par ## $par ## K a n x ## 36.2213653 0.6481563 1.1401725 -0.5659189 ## ## $value ## [1] 6069.676 ## ## $counts ## function gradient ## 74 74 ## ## $convergence ## [1] 0 ## ## $message ## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot; df_16882 %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-05-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-06-01&quot;) &amp; !is.infinite(J) | Date_Time &gt; as.POSIXct(&quot;2020-10-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-11-01&quot;) &amp; !is.infinite(J)) %&gt;% mutate(predicted = (K*exponent(x = as.numeric(Depth) - a, pow = n)) * exponent(x = (1 + x * J), pow = (1/2))) %&gt;% ggplot() + geom_point(aes(as.numeric(Depth), as.numeric(Flow), color = &quot;measured&quot;), alpha = 0.5) + geom_point(aes(as.numeric(Depth), as.numeric(predicted), color = &quot;predicted&quot;), alpha = 0.2) + #scale_y_log10() + theme_ms() ## Warning: Removed 1 rows containing missing values (geom_point). df_16882 %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-05-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-06-01&quot;) &amp; !is.infinite(J) | Date_Time &gt; as.POSIXct(&quot;2020-10-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-11-01&quot;) &amp; !is.infinite(J)) %&gt;% mutate(predicted = (K*exponent(x = as.numeric(Depth) - a, pow = n)) * exponent(x = (1 + x * J), pow = (1/2))) %&gt;% ggplot() + geom_point(aes(as.numeric(Flow), as.numeric(predicted), color = &quot;measured&quot;), alpha = 0.5) + geom_abline(slope = 1) + #scale_y_log10() + scale_x_log10() + theme_ms() ## Warning: Removed 1 rows containing missing values (geom_point). df_16882 %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-05-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-06-01&quot;) &amp; !is.infinite(J) | Date_Time &gt; as.POSIXct(&quot;2020-10-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-11-01&quot;) &amp; !is.infinite(J)) %&gt;% mutate(predicted = (K*exponent(x = as.numeric(Depth) - a, pow = n)) * exponent(x = (1 + x * J), pow = (1/2))) -&gt; df_16882_spring df_16882_spring_results &lt;- tibble(Site = &quot;16882:Spring&quot;, K = K, a = a, n = n, x = x, NSE = hydroGOF::NSE(df_16882_spring$predicted, as.numeric(df_16882_spring$Flow)), RMSE = hydroGOF::rmse(df_16882_spring$predicted, as.numeric(df_16882_spring$Flow))) df_16882_spring_results ## # A tibble: 1 x 7 ## Site K a n x NSE RMSE ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 16882:Spring 36.2 0.648 1.14 -0.566 0.963 1.75 par &lt;- c(K = 1, a = 5, n = 2, x = 50) ## limits to the parameter space lower &lt;- c(.00001, 0, 0.00001, -10) upper &lt;- c(200, 10, 10, 100) optim.par &lt;- optim(par = par, fn = SSE, data = df_16882 %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-11-01&quot;) &amp; !is.infinite(J)), lower = lower, upper = upper, method = &quot;L-BFGS-B&quot;) K &lt;- optim.par$par[[1]] a &lt;- optim.par$par[[2]] n &lt;- optim.par$par[[3]] x &lt;- optim.par$par[[4]] optim.par ## $par ## K a n x ## 8.0785577 0.8679692 2.3945289 1.6137518 ## ## $value ## [1] 5574.524 ## ## $counts ## function gradient ## 116 116 ## ## $convergence ## [1] 0 ## ## $message ## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot; df_16882 %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-11-01&quot;) &amp; !is.infinite(J)) %&gt;% mutate(predicted = (K*exponent(x = as.numeric(Depth) - a, pow = n)) * exponent(x = (1 + x * J), pow = (1/2))) %&gt;% ggplot() + geom_point(aes(as.numeric(Depth), as.numeric(Flow), color = &quot;measured&quot;), alpha = 0.5) + geom_point(aes(as.numeric(Depth), as.numeric(predicted), color = &quot;predicted&quot;), alpha = 0.2) + #scale_y_log10() + theme_ms() ## Warning: Removed 1 rows containing missing values (geom_point). df_16882 %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-11-01&quot;) &amp; !is.infinite(J)) %&gt;% mutate(predicted = (K*exponent(x = as.numeric(Depth) - a, pow = n)) * exponent(x = (1 + x * J), pow = (1/2))) %&gt;% ggplot() + geom_point(aes(as.numeric(Flow), as.numeric(predicted), color = &quot;measured&quot;), alpha = 0.5) + geom_abline(slope = 1) + #scale_y_log10() + scale_x_log10() + theme_ms() ## Warning: Removed 1 rows containing missing values (geom_point). df_16882 %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-11-01&quot;) &amp; !is.infinite(J)) %&gt;% mutate(predicted = (K*exponent(x = as.numeric(Depth) - a, pow = n)) * exponent(x = (1 + x * J), pow = (1/2))) -&gt; df_16882_winter df_16882_winter_results &lt;- tibble(Site = &quot;16882:Winter&quot;, K = K, a = a, n = n, x = x, NSE = hydroGOF::NSE(df_16882_winter$predicted, as.numeric(df_16882_winter$Flow)), RMSE = hydroGOF::rmse(df_16882_winter$predicted, as.numeric(df_16882_winter$Flow))) df_16882_winter_results ## # A tibble: 1 x 7 ## Site K a n x NSE RMSE ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 16882:Winter 8.08 0.868 2.39 1.61 0.946 9.48 "]]
