[["index.html", "Exploring Thompsons Creek Stage Discharge Data About Introduction Method Results", " Exploring Thompsons Creek Stage Discharge Data 2021-03-04 ## readr imports data library(readr) ## tibbles are advanced fancy dataframes library(tibble) ## dplyr for data handling and piping functions library(dplyr) ## ggplot for plots library(ggplot2) ## stringr to read and manipulate strings library(stringr) ## here is a function to ensure file paths are correct library(here) ## units and ggforce facilitate attaching units to data library(units) library(ggforce) ## hrbrtheme is optional, I use it to pretty my plots library(hrbrthemes) ## patchwork support arranging multiple ggplots into one plot library(patchwork) ## lubridate provides functions for handling time and date library(lubridate) ## purrr lets us use map_ functions as an alternative to loops library(purrr) ## hydroGOF provide goodness of fit metrics (NSE, RMSE, etc.) library(hydroGOF) ## tsibble and imputeTS will allow some simple time series interpolation library(tsibble) library(imputeTS) ## gt library(gtsummary) ## nls.multstart fits non-linear least squares using the Levenberg-Marquardt algorithm with multiple starting values. library(nls.multstart) ## set some options update_geom_font_defaults(font_rc) units_options(parse = FALSE) ## some custom functions theme_ms &lt;- function(...) { theme_ipsum_rc(plot_margin = margin(10,10,10,10), axis_title_just = &quot;c&quot;) + theme(legend.position = &quot;bottom&quot;, panel.background = element_rect(fill = &quot;white&quot;, colour = NA), panel.border = element_rect(fill = NA, colour = &quot;grey20&quot;), ...) } exponent &lt;- function(x, pow) { (abs(x)^pow)*sign(x) } About This document walks through some exploratory data analysis to develop rating curves and streamflow predictions on Thompsons Creek. The purpose is to utilize (1) instantaneous streamflows measured during periodic deployments of bottom mounted doppler units and (2) instantaneous depth measurements from water level data loggers deployed long-term in-stream to create and update rating curves. The rating curves will be utilized to calculate streamflow over the HOBO pressure transducer deployment period (approximately 1-yr). The resulting data will be used to create and validate regression and DAR streamflow estimates in Thompsons creek over a 10-15 year period. Introduction Due to the high costs associated with continuous in-stream measurements of stream discharge, it is preferable to estimate discharge using stream height measurements. Continuous measurements of stream height can be accomplished inexpensively using pressure transducers. When supplemented with periodic discharge measurements, a power function can relate stream height and discharge (Venetis 1970): \\[\\begin{equation} Q = K(H-H_0)^z \\tag{1} \\end{equation}\\] where: \\(Q\\) represents steady state discharge, \\(H\\) represents stream height (stage), \\(H_0\\) is the stage at zero discharge; \\(K\\) and \\(z\\) are rating curve constants. Following convention, \\(Q\\) and \\(H\\) are often log-transformed prior to parameter estimation. Unsteady flows occur when the rising and falling stages of a stream hydrograph result in different discharges at identical stream heights. This resulting hysteresis-affected rating curve will present as a loop as opposed to a line. The modified Jones formula described by Petersen-Øverleir (2006) and Zakwan (2018) may be used: \\[\\begin{equation} Q = K(h-a)^n\\times\\sqrt{1 + x\\frac{\\partial h}{\\partial t}} \\tag{2} \\end{equation}\\] where \\(Q\\) is discharge and \\(h\\) is stream height. The partial first order derivative\\(\\frac{\\partial h}{\\partial t}\\) is approximated as \\(J\\) using finite differences: \\[\\begin{equation} J(h_t) = (h_{t+1}-h_{t-1})/\\Delta t \\tag{3} \\end{equation}\\] where \\(h_t\\) is the stream height at time \\(t\\) and \\(\\Delta t\\) is the time interval. This can be considered the slope or instantaneous rate of change for the function between stream height and time which is estimated using measured stream height values. \\(K\\), \\(a\\), \\(n\\), and \\(x\\) are rating curve constants. A number of different methods are available to solve for the rating curve parameters. We use non-linear least squares regression to minimize the residual sum of square error (SSE) of the rating curve parameters. The residual SSE is calculated as: \\[\\begin{equation} SSE = \\sum\\limits_{i=1}^N[X-Y]^2 \\tag{4} \\end{equation}\\] where: \\(X\\) is the measured value and \\(Y\\) is the predicted value. Nonlinear optimization methods search though parameter combinations to minimize the objective function (residual SSE in this case). Petersen-Øverleir (2006) applied the Nelder-Mead algorithm to solve the Jones formula. Zakwan (2018) present spreadsheet based nonlinear optimization methods using generalized reduced gradient and genetic algorithm. Most methods require careful planning for parameter starting values that are somewhat near the global minimum value or risk identifying a alternative local minimum values. To reduce the likelihood of convergance on local minimum, the nls.multstart package in R provides functionality to iterate non-linear least squares optimization over many different starting values (Padfield and Matheson 2020). Method Data collection Water level data loggers (HOBO U20 Series Water Level Data Loggers) were deployed at TCEQ SWQM stations 16396, 16397, and 16882 (Table ??). An additional data logger was deployed at … to provide ambient atmospheric pressure corrections for the data loggers deployed underwater. Water level data loggers were deployed near continuously from 2020-03-02 through 2021-..-… and setup to record water level at 15-minute intervals. ## make a list of files to import file_paths &lt;- paste0(here(&quot;Data/Hobo&quot;), &quot;/&quot;, list.files(path = here(&quot;Data/Hobo&quot;), pattern = &quot;.csv&quot;)) ## create a blank tibble to fill hobo_df &lt;- tibble() ## loop through file paths to read each file for (i in file_paths) { x &lt;- read_csv( i, skip = 2, col_names = c( &quot;Row&quot;, &quot;Date&quot;, &quot;Time&quot;, &quot;Abs_Pres&quot;, &quot;Temp&quot;, &quot;Bar_Pressure&quot;, &quot;Water_Level&quot;, &quot;Coupler_Detached&quot;, &quot;Coupler_Attached&quot;, &quot;Stopped&quot;, &quot;EOF&quot; ), col_types = &quot;nccnnnncccc&quot; ) x$file &lt;- i hobo_df &lt;- bind_rows(hobo_df, x) rm(x) } ## clean up the dataframe hobo_df &lt;- hobo_df %&gt;% mutate( ## regex extracts site number from file path Site = str_extract(file, &quot;\\\\d{1,6}&quot;), ## convert date and time columns to date/time format dt = paste(Date, Time), Date_Time = as.POSIXct(paste(Date, Time), tz = &quot;Etc/GMT-6&quot;, format = &quot;%m/%d/%y %I:%M:%S %p&quot;)) %&gt;% mutate(Site = as.factor(Site)) %&gt;% ## select the columns we need to keep dplyr::select(Abs_Pres, Temp, Water_Level, Site, Date_Time) %&gt;% ## filter rows without water_level dplyr::filter(!is.na(Water_Level)) ## attach units to our columns units(hobo_df$Water_Level) &lt;- as_units(&quot;ft&quot;) units(hobo_df$Temp) &lt;- as_units(&quot;°F&quot;) units(hobo_df$Abs_Pres) &lt;- as_units(&quot;psi&quot;) ## report summary stats hobo_df %&gt;% select(Site, Water_Level) %&gt;% mutate(Water_Level = as.numeric(Water_Level)) %&gt;% tbl_summary(by = Site) %&gt;% add_n() %&gt;% modify_header(label = &quot;**Variable**&quot;) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #gzunngywdc .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #gzunngywdc .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gzunngywdc .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #gzunngywdc .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #gzunngywdc .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gzunngywdc .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gzunngywdc .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #gzunngywdc .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #gzunngywdc .gt_column_spanner_outer:first-child { padding-left: 0; } #gzunngywdc .gt_column_spanner_outer:last-child { padding-right: 0; } #gzunngywdc .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #gzunngywdc .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #gzunngywdc .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #gzunngywdc .gt_from_md > :first-child { margin-top: 0; } #gzunngywdc .gt_from_md > :last-child { margin-bottom: 0; } #gzunngywdc .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #gzunngywdc .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #gzunngywdc .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gzunngywdc .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #gzunngywdc .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gzunngywdc .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #gzunngywdc .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #gzunngywdc .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gzunngywdc .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gzunngywdc .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #gzunngywdc .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gzunngywdc .gt_sourcenote { font-size: 90%; padding: 4px; } #gzunngywdc .gt_left { text-align: left; } #gzunngywdc .gt_center { text-align: center; } #gzunngywdc .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #gzunngywdc .gt_font_normal { font-weight: normal; } #gzunngywdc .gt_font_bold { font-weight: bold; } #gzunngywdc .gt_font_italic { font-style: italic; } #gzunngywdc .gt_super { font-size: 65%; } #gzunngywdc .gt_footnote_marks { font-style: italic; font-size: 65%; } Variable N 16396, N = 29,8211 16397, N = 29,8231 16882, N = 30,5051 Water_Level 90,149 1.72 (1.66, 1.82) 1.42 (1.06, 1.79) 2.39 (2.35, 2.44) 1 Median (IQR) Periodic streamflow measurements were made at each SWQM site using a bottom-mounted multi-beam Doppler flow meter (Son-Tek IQ Plus) (Figure ??). The Son-Tek IQ Plus measures cross sectional area, stream height, and velocity. Using these measurements, the device utilizes an index velocity method to report instantaneous discharge. The streamflow measurement device were deployed for a few days at a time to capture the full hydrograph under varying flow conditions at each SWQM station. Only two Doppler flow meters were available, so deployments rotated between stations. Additionally, one device stopped working and was under repair for a few months. Streamflow was recorded at 15-minute intervals. During data exploration it was evident there was excess noise in the data at low flows for each station. During periods of stagnant or near stagnant conditions the doppler flow meters recorded highly variable stream velocities and reported unrealistic flows. Due to the excess data noise, periods of extreme low or stagnant flow were cleaned from the data record. Future deployments will need to consider under what conditions long term deployments are appropriate. For small streams such as these, periodic storm flow deployments are likely the most appropriate deployment. ## make a list of files to import file_paths &lt;- paste0(here(&quot;Data/IQPlus&quot;), &quot;/&quot;, list.files(path = here(&quot;Data/IQPlus&quot;), pattern = &quot;.csv&quot;)) ## create a blank tibble to fill iqplus_df &lt;- tibble() ## loop through file paths to read each file for (i in file_paths) { x &lt;- read_csv( i, col_types = &quot;nc______n__n______________________nn______n_________&quot; ) x$file &lt;- i iqplus_df &lt;- bind_rows(iqplus_df, x) rm(x) } iqplus_df &lt;- iqplus_df %&gt;% mutate( ## regex extracts site number from file path Site = str_extract(file, &quot;\\\\d{1,6}&quot;)) %&gt;% ## use `dplyr::` to specify which rename function to use, just in case dplyr::rename(Sample_Number =`Sample number`, Date_Time = `Sample time`, Depth = `Depth (ft)`, Flow = `Flow (ft³/s)`, System_In_Water = `System in water (%)`, System_Status = `System status (status codes)`, Index_Velocity = `Velocity (mean) (ft/s)`) %&gt;% dplyr::select(-c(Sample_Number, file)) %&gt;% mutate(Date_Time = as.POSIXct(Date_Time, tz = &quot;Etc/GMT-6&quot;, format = &quot;%Y-%m-%d %H:%M:%S&quot;)) ## attach units to our columns units(iqplus_df$Depth) &lt;- as_units(&quot;ft&quot;) units(iqplus_df$Flow) &lt;- as_units(&quot;ft^3/s&quot;) units(iqplus_df$Index_Velocity) &lt;- as_units(&quot;ft/s&quot;) ## some data cleaning iqplus_df %&gt;% filter(System_Status == 0, System_In_Water == 100, #as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Site == &quot;16396&quot; &amp; Date_Time &gt;= as.POSIXct(&quot;2020-05-03&quot;) &amp; Date_Time &lt;= as.POSIXct(&quot;2020-05-31&quot;) &amp; as.numeric(Depth) &gt;= 0.875 | Site == &quot;16396&quot; &amp; Date_Time &gt;= as.POSIXct(&quot;2020-12-01&quot;) &amp; Date_Time &lt;= as.POSIXct(&quot;2021-01-31&quot;) &amp; as.numeric(Depth) &gt;= 0.875 | Site == &quot;16397&quot; &amp; Date_Time &gt;= as.POSIXct(&quot;2020-12-15&quot;) &amp; Date_Time &lt;= as.POSIXct(&quot;2020-12-31&quot;) &amp; as.numeric(Depth) &gt;= 0.875 | Site == &quot;16397&quot; &amp; Date_Time &gt;= as.POSIXct(&quot;2021-01-05&quot;) &amp; as.numeric(Depth) &gt;= 0.875 | # as.numeric(Depth) &gt; 2 | Site == &quot;16882&quot; &amp;## possible sedimentation at low flows, removing low flow measurements. Date_Time &gt;= as.POSIXct(&quot;2020-05-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-06-01&quot;) &amp; as.numeric(Depth) &gt;= 0.875 | Site == &quot;16882&quot; &amp; ## possible sedimentation at low flows, removing low flow measurements. Date_Time &gt;= as.POSIXct(&quot;2020-10-11&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-10-31&quot;) &amp; as.numeric(Depth) &gt;= 0.875 | Site == &quot;16882&quot; &amp; Date_Time &gt;= as.POSIXct(&quot;2020-12-10&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) -&gt; iqplus_df ggplot(iqplus_df) + geom_point(aes(Date_Time, Flow), alpha = 0.2) + facet_wrap(~Site, ncol = 1, scales = &quot;free_y&quot;) + labs(x = &quot;Date&quot;) + theme_ms() Figure 1: Period of recorded data at each station. ## In order to join the hobo measured depth to the IQ streamflow measurements ## we need to interpolate measured Depth to every minute because the depths are ## offset. Then we can join the data. we will use linear interpolation. ## I need a pipe friendly function that assigns an attribute to ## a tibble (tsibble) and returns a tibble (tsibble) pipe_attr &lt;- function(df) { attr(df, &quot;interval&quot;) &lt;- new_interval(minute = 1) return(df) } ## use purrr::map to run interpolation on each site hobo_df %&gt;% split(.$Site) %&gt;% map(~dplyr::mutate(.x, Date_Time = round_date(.x$Date_Time, unit = &quot;minute&quot;))) %&gt;% map(~as_tsibble(.x, key = Site, index = Date_Time)) %&gt;% map(~pipe_attr(.x)) %&gt;% map(~fill_gaps(.x)) %&gt;% map(~mutate(.x, Water_Level = na_interpolation(as.numeric(Water_Level), option = &quot;linear&quot;))) %&gt;% bind_rows() %&gt;% as_tibble() %&gt;% select(Water_Level, Site, Date_Time) -&gt; hobo_df_interpolated ## replace Depth in iqplus_df with Water_Level reading from Hobo ## this is the dataframe we will develop rating curves from. iqplus_df %&gt;% left_join(hobo_df_interpolated, by = c(&quot;Site&quot; = &quot;Site&quot;, &quot;Date_Time&quot; = &quot;Date_Time&quot;)) %&gt;% select(Date_Time, Flow, System_In_Water, System_Status, Site, Water_Level) %&gt;% rename(Depth = Water_Level) %&gt;% mutate(Depth = set_units(Depth, &quot;ft&quot;)) -&gt; iqplus_df Rating curve development In-stream and stream bank conditions change through the year due to plant growth, plant dieback, sedimentation, erosion, and other processes. These changing conditions can necessitate the development of multiple rating curves. Exploratory data analysis was used to identify periods of change and the potential for hysteresis affected rating curves. Once rating curve periods and appropriate formulas were determined, rating curve parameters in formulas (1) and (2) were estimated by non-linear least squares regression using the nls.multstart package in R (Padfield and Matheson 2020). This method utilizes the Levenberg-Marquardt algorithm and multiple starting values to find the global minimum SSE value. Individual rating curves were used to estimate streamflows using the measured stream heights. Nash-Sutcliffe Efficiency (NSE) and normalized Root Mean Square Error was used to evaluate goodness-of-fit between measured and estimated streamflow. NSE is a normalized statistic that evaluates the relative residual variance against the measured data variance and is calculated as: \\[\\begin{equation} NSE = 1 - \\frac{\\sum\\limits_{t=1}^T(Q^t_{sim}-Q^t_{obs})^2}{\\sum\\limits_{t=1}^T(Q^t_{obs}-\\bar{Q}_{obs})^2} \\tag{5} \\end{equation}\\] Where \\(\\bar{Q}_{obs}\\) is the mean of observed discharges, \\(Q^t_{sim}\\) is the estimated discharge at time \\(t\\), and \\(Q^t_{obs}\\) is observed discharge at time \\(t\\). Values of NSE range from \\(-\\infty\\) to 1, where 1 indicates perfect predicitive performance. NSE of zero indicates the model has the same predictive performance as the mean of the dataset. The nRMSE is a percentage based metric that describes the difference between predicted and measured discharge values: \\[\\begin{equation} nRMSE = \\frac{RMSE}{Q_{max}-Q_{min}}, \\quad \\textrm{where} \\quad RMSE = \\sqrt{\\frac{\\sum_{t=1}^{n}{(Q_t-\\hat{Q}_t)^2}}{n}} \\tag{6} \\end{equation}\\] Where \\(Q_i\\) is the observed discharge at time \\(t\\), \\(\\hat{Q}_t\\) is the estimated discharge at time \\(t\\), \\(n\\) is the number of samples, \\(Q_max\\) and \\(Q_min\\) are the maximum and minimum observed discharges. The resulting nRMSE calculation is a percentage value. Results Site 16396 Based on exploratory analysis, two rating curves were developed for site 16396. The rating curve periods were 2020-03-03 through 2020-11-30 and 2020-12-01 through 2021-01-31. Due to apparent unsteady flow in the observed hydrogaphs, we applied the Jones formula (Formula(2)). Both time periods resulted in a rating curve with NSE greater than 0.97 and nRMSE less than 3% indicating excellent fit (Table 1; Figure 2). Figure 2 does indicate some biased flow estimates at extremely low flow measurements. This is attributed to variability in flows recorded by the doppler flow meter at low flows. ## Make dataframe for site 16396 before december iqplus_df %&gt;% filter(Site == &quot;16396&quot;, Date_Time &lt; as.Date(&quot;2020-12-01&quot;)) %&gt;% arrange(Date_Time) %&gt;% mutate(time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;))) %&gt;% group_split(cumsum(diff_time &gt; 8)) %&gt;% ## remove events where max flow did not go over 10 cfs keep(~ max(as.numeric(.x$Flow)) &gt; 10) %&gt;% map(~select(.x, Date_Time, Depth, Flow)) %&gt;% map(~mutate(.x, time_lag = lag(Date_Time, default = Date_Time[1]), time_lead = lead(Date_Time), diff_time = as.numeric(difftime(time_lead,time_lag, units = &quot;hours&quot;)), diff_depth = lead(Depth) - lag(Depth))) %&gt;% imap(~mutate(.x, event = as.character(.y))) %&gt;% bind_rows() %&gt;% filter(!is.na(diff_depth)) %&gt;% mutate(J = as.numeric(diff_depth)/as.numeric(diff_time)) -&gt; df_16396_2020_03 ## Make dataframe for site 16396 Dec 2020 through January 2021 iqplus_df %&gt;% filter(Site == &quot;16396&quot;, Date_Time &gt;= as.Date(&quot;2020-12-01&quot;) &amp; Date_Time &lt;= as.Date(&quot;2021-02-01&quot;)) %&gt;% arrange(Date_Time) %&gt;% mutate(time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;))) %&gt;% group_split(cumsum(diff_time &gt; 8)) %&gt;% ## remove events where max flow did not go over 10 cfs keep(~ max(as.numeric(.x$Flow)) &gt; 10) %&gt;% map(~select(.x, Date_Time, Depth, Flow)) %&gt;% map(~mutate(.x, time_lag = lag(Date_Time, default = Date_Time[1]), time_lead = lead(Date_Time), diff_time = as.numeric(difftime(time_lead,time_lag, units = &quot;hours&quot;)), diff_depth = lead(Depth) - lag(Depth))) %&gt;% imap(~mutate(.x, event = as.character(.y))) %&gt;% bind_rows() %&gt;% filter(!is.na(diff_depth)) %&gt;% mutate(J = as.numeric(diff_depth)/as.numeric(diff_time)) -&gt; df_16396_2020_12 ## use nls to estimate parameters in Jones formula jones_form &lt;- formula(log(as.numeric(Flow)) ~ K*exponent(x = log(as.numeric(Depth)) - a, pow = n) * exponent(x = (1 + x * J), pow = (1/2))) ## some starting paremeters. nls_multstart will use multiple ## starting parameters and model selection to find ## global minimum start_lower &lt;- list(K = 0, a = 0, n = 0, x = -5) start_upper &lt;- list(K = 10, a = 10, n = 5, x = 5) ## fit nls rc_16396_2020_03 &lt;- nls_multstart(jones_form, data = df_16396_2020_03, iter = 1000, start_lower = start_lower, start_upper = start_upper, convergence_count = FALSE, supp_errors = &quot;Y&quot;) ## set parameter starting limits start_lower &lt;- list(K = -100, a = 0, n = 0, x = -5000) start_upper &lt;- list(K = 100, a = 1000, n = 50, x = 5000) ## fit nls rc_16396_2020_12 &lt;- nls_multstart(jones_form, data = df_16396_2020_12, iter = 1000, start_lower = start_lower, start_upper = start_upper, convergence_count = FALSE, supp_errors = &quot;Y&quot;) ## setup dataframe with parameter results. Will use this later to report parameters and GOF metrics df_results_16369 &lt;- tibble(Site = c(&quot;16396&quot;,&quot;16396&quot;), Period = c(&quot;2020-03-01 : 2020-11-30&quot;, &quot;2020-12-01 : 2021-01-31&quot;), K = c(coefficients(rc_16396_2020_03)[[&quot;K&quot;]], coefficients(rc_16396_2020_12)[[&quot;K&quot;]]), a = c(coefficients(rc_16396_2020_03)[[&quot;a&quot;]], coefficients(rc_16396_2020_12)[[&quot;a&quot;]]), n = c(coefficients(rc_16396_2020_03)[[&quot;n&quot;]], coefficients(rc_16396_2020_12)[[&quot;n&quot;]]), x = c(coefficients(rc_16396_2020_03)[[&quot;x&quot;]], coefficients(rc_16396_2020_12)[[&quot;x&quot;]])) ## Develop rating curve predictions and ## create table with GOF metrics df_16396_2020_03 %&gt;% filter(!is.na(J)) %&gt;% mutate(predicted = exp(predict(rc_16396_2020_03, .))) -&gt; df_16396_2020_03 df_16396_2020_12 %&gt;% filter(!is.na(J)) %&gt;% mutate(predicted = exp(predict(rc_16396_2020_12, .))) -&gt; df_16396_2020_12 df_results_16369 %&gt;% mutate(NSE = c( hydroGOF::NSE(df_16396_2020_03$predicted, as.numeric(df_16396_2020_03$Flow)), hydroGOF::NSE(df_16396_2020_12$predicted, as.numeric(df_16396_2020_12$Flow))), nRMSE = c(hydroGOF::nrmse(df_16396_2020_03$predicted, as.numeric(df_16396_2020_03$Flow), norm = &quot;maxmin&quot;), hydroGOF::nrmse(df_16396_2020_12$predicted, as.numeric(df_16396_2020_12$Flow), norm = &quot;maxmin&quot;)) ) -&gt; df_results_16369 ##display table kable(df_results_16369, caption = &quot;Rating curve parameter estimates and goodness-of-fit metrics for station 16369.&quot;) Table 1: Rating curve parameter estimates and goodness-of-fit metrics for station 16369. Site Period K a n x NSE nRMSE 16396 2020-03-01 : 2020-11-30 4.700924 0.3324034 0.5018387 -0.1250084 0.9793704 1.7 16396 2020-12-01 : 2021-01-31 4.393197 0.1780423 0.6565699 0.0975950 0.9779719 2.0 ## plot rating curve results p1 &lt;- ggplot(df_16396_2020_03) + geom_point(aes(as.numeric(predicted), as.numeric(Flow), color = &quot;Rating curve prediction against measured flow&quot;), alpha = 0.25) + geom_abline(aes(slope = 1, intercept = 0, linetype = &quot;1:1 line&quot;)) + scale_x_continuous(name = &quot;Rating curve flow estimate [cfs]&quot;, trans = &quot;log10&quot;) + scale_y_continuous(name = &quot;Measured flow [cfs]&quot;, trans = &quot;log10&quot;) + theme_ms() + labs(subtitle = &quot;March-November&quot;) + theme(legend.title = element_blank(), legend.position = &quot;none&quot;) p2 &lt;- ggplot(df_16396_2020_03) + geom_point(aes(as.numeric(Flow), Depth, color = &quot;Measured&quot;)) + geom_path(aes(as.numeric(Flow), Depth, color = &quot;Measured&quot;, linetype = &quot;Measured&quot;), alpha = 0.5) + geom_point(aes(as.numeric(predicted), Depth, color = &quot;Predicted&quot;)) + geom_path(aes(as.numeric(predicted), Depth, color = &quot;Predicted&quot;, linetype = &quot;Predicted&quot;), alpha = 0.5) + scale_color_discrete(&quot;&quot;) + scale_linetype_discrete(&quot;&quot;) + scale_x_continuous(&quot;Flow [cfs]&quot;, trans = &quot;log10&quot;) + labs(subtitle = &quot;March-November&quot;) + theme_ms() + theme(legend.position = &quot;none&quot;) p3 &lt;- ggplot(df_16396_2020_12) + geom_point(aes(as.numeric(predicted), as.numeric(Flow), color = &quot;Rating curve prediction against measured flow&quot;), alpha = 0.25) + geom_abline(aes(slope = 1, intercept = 0, linetype = &quot;1:1 line&quot;)) + scale_x_continuous(name = &quot;Rating curve flow estimate [cfs]&quot;, trans = &quot;log10&quot;) + scale_y_continuous(name = &quot;Measured flow [cfs]&quot;, trans = &quot;log10&quot;) + theme_ms() + labs(subtitle = &quot;December-January&quot;) + theme(legend.title = element_blank()) p4 &lt;- ggplot(df_16396_2020_12) + geom_point(aes(as.numeric(Flow), Depth, color = &quot;Measured&quot;)) + geom_path(aes(as.numeric(Flow), Depth, color = &quot;Measured&quot;, linetype = &quot;Measured&quot;), alpha = 0.5) + geom_point(aes(as.numeric(predicted), Depth, color = &quot;Predicted&quot;)) + geom_path(aes(as.numeric(predicted), Depth, color = &quot;Predicted&quot;, linetype = &quot;Predicted&quot;), alpha = 0.5) + scale_color_discrete(&quot;&quot;) + scale_linetype_discrete(&quot;&quot;) + scale_x_continuous(&quot;Flow [cfs]&quot;, trans = &quot;log10&quot;) + labs(subtitle = &quot;December-January&quot;) + theme_ms() (p1 + p2) / (p3 + p4) + plot_annotation(tag_levels = &quot;A&quot;) Figure 2: Scatter plot of rating curve estimated flows against measured flows (A, C) and stage discharge predictions (B, D) for each rating curve period at station 16396. Site 16397 Exploratory analysis indicated pooled conditions when during doppler flow meter deployment from August 2020 through November 2020. A single rating curve was developed at this site using the power function (Formula (1)) since unsteady flow conditions were not observed in the hydrographs. Rating curve predictions resulted in NSE greater than 0.94 indicating excellent fit (Table 1). The nRMSE was less than 6%, which is likely a good result for the smaller sample sized obtained at this station and probably influenced by the observed low flow variance (Table 1; Figure 2). ## setup dataframe to fit rating curve to 16397 iqplus_df %&gt;% filter(Site == &quot;16397&quot;) %&gt;% arrange(Date_Time) %&gt;% mutate(time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;))) %&gt;% group_split(cumsum(diff_time &gt; 8)) %&gt;% map(~select(.x, Date_Time, Depth, Flow)) %&gt;% map(~mutate(.x, time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;)), diff_depth = c(0, diff(.x$Depth)))) %&gt;% imap(~mutate(.x, event = as.character(.y))) %&gt;% bind_rows() %&gt;% filter(!is.na(diff_depth)) %&gt;% mutate(J = as.numeric(diff_depth)/as.numeric(diff_time)) -&gt; df_16397 ## power function power_form &lt;- formula(log(as.numeric(Flow)) ~ K*(log(as.numeric(Depth)) - H_0)^Z) ## parameter starting limits start_lower &lt;- list(K = -10, Z = 0.0001, H_0 = 0.0001) start_upper &lt;- list(K = 10, Z = 10, H_0 = 8) rc_16397 &lt;- nls_multstart(power_form, data = df_16397, iter = 1000, start_lower = start_lower, start_upper = start_upper, convergence_count = FALSE, supp_errors = &quot;Y&quot;) ## setup dataframe with parameter results. Will use this later to report parameters and GOF metrics df_results_16397 &lt;- tibble(Site = c(&quot;16397&quot;), Period = c(&quot;2020-03-01 : 2020-01-30&quot;), K = coefficients(rc_16397)[[&quot;K&quot;]], H_0 = coefficients(rc_16397)[[&quot;H_0&quot;]], Z = coefficients(rc_16397)[[&quot;Z&quot;]]) df_16397 %&gt;% mutate(predicted = exp(predict(rc_16397, .))) -&gt; df_16397 df_results_16397 %&gt;% mutate(NSE = hydroGOF::NSE(df_16397$predicted, as.numeric(df_16397$Flow)), nRMSE = hydroGOF::nrmse(df_16397$predicted, as.numeric(df_16397$Flow), norm=&quot;maxmin&quot;)) -&gt; df_results_16397 kable(df_results_16397, caption = &quot;Rating curve parameter estimates and goodness-of-fit metrics for station 16397.&quot;) Table 2: Rating curve parameter estimates and goodness-of-fit metrics for station 16397. Site Period K H_0 Z NSE nRMSE 16397 2020-03-01 : 2020-01-30 0.0008266 -2.404998 5.660803 0.9517189 4.9 ## plot rating curve results p1 &lt;- df_16397 %&gt;% mutate(predicted = set_units(predicted, &quot;ft^3/s&quot;)) %&gt;% ggplot() + geom_point(aes(as.numeric(predicted), as.numeric(Flow), color = &quot;Rating curve prediction against measured flow&quot;), alpha = 0.9) + geom_abline(aes(slope = 1, intercept = 0, linetype = &quot;1:1 line&quot;)) + scale_x_continuous(name = &quot;Rating curve flow estimate [cfs]&quot;, trans = &quot;log10&quot;) + scale_y_continuous(name = &quot;Measured flow [cfs]&quot;, trans = &quot;log10&quot;) + theme_ms() + theme(legend.title = element_blank()) p2 &lt;- ggplot(df_16397) + geom_point(aes(as.numeric(Flow), Depth, color = &quot;Measured&quot;)) + geom_point(aes(as.numeric(predicted), Depth, color = &quot;Predicted&quot;)) + scale_color_discrete(&quot;&quot;) + scale_x_continuous(&quot;Flow [cfs]&quot;, trans = &quot;log10&quot;) + theme_ms() p1 + p2 + plot_annotation(tag_levels = &quot;A&quot;) Figure 3: Scatter plot of rating curve estimated flows against measured flows (A) and stage discharge predictions (B) for station 16397. Site 16882 Based on exploratory analysis, three rating curves were developed for site 16396. The rating curve periods were 2020-03-03 through 2020-05-30; 2020-06-01 through 2020-10-31; and 2020-11-01 through 2021-01-31. Due to apparent unsteady flow in the observed hydrogaphs, we applied the Jones formula (Formula(2)). ## make 3 different dataframes to fit jones formula to. iqplus_df %&gt;% filter(Site == &quot;16882&quot;) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-05-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-05-31&quot;)) %&gt;% arrange(Date_Time) %&gt;% mutate(time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;))) %&gt;% #filter(as.numeric(Depth) &gt;= 2.36) %&gt;% group_split(cumsum(diff_time &gt; 8)) %&gt;% ## remove events where max flow did not go over 10 cfs #keep(~ max(as.numeric(.x$Flow)) &gt; 10) %&gt;% map(~select(.x, Date_Time, Depth, Flow)) %&gt;% map(~mutate(.x, time_lag = lag(Date_Time, default = Date_Time[1]), time_lead = lead(Date_Time), diff_time = as.numeric(difftime(time_lead,time_lag, units = &quot;hours&quot;)), diff_depth = lead(Depth) - lag(Depth))) %&gt;% imap(~mutate(.x, event = as.character(.y))) %&gt;% bind_rows() %&gt;% filter(!is.na(diff_depth)) %&gt;% mutate(J = as.numeric(diff_depth)/as.numeric(diff_time)) -&gt; df_16882_2020_03 iqplus_df %&gt;% filter(Site == &quot;16882&quot;) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-10-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-10-31&quot;)) %&gt;% arrange(Date_Time) %&gt;% mutate(time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;))) %&gt;% group_split(cumsum(diff_time &gt; 8)) %&gt;% ## remove events where max flow did not go over 10 cfs keep(~ max(as.numeric(.x$Flow)) &gt; 10) %&gt;% map(~select(.x, Date_Time, Depth, Flow)) %&gt;% map(~mutate(.x, time_lag = lag(Date_Time, default = Date_Time[1]), time_lead = lead(Date_Time), diff_time = as.numeric(difftime(time_lead,time_lag, units = &quot;hours&quot;)), diff_depth = lead(Depth) - lag(Depth))) %&gt;% imap(~mutate(.x, event = as.character(.y))) %&gt;% bind_rows() %&gt;% filter(!is.na(diff_depth)) %&gt;% mutate(J = as.numeric(diff_depth)/as.numeric(diff_time)) -&gt; df_16882_2020_10 iqplus_df %&gt;% filter(Site == &quot;16882&quot;) %&gt;% filter(Date_Time &gt;= as.POSIXct(&quot;2020-11-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2021-01-31&quot;)) %&gt;% arrange(Date_Time) %&gt;% mutate(time_lag = lag(Date_Time, default = Date_Time[1]), diff_time = as.numeric(difftime(Date_Time, time_lag, units = &quot;hours&quot;))) %&gt;% group_split(cumsum(diff_time &gt; 8)) %&gt;% ## remove events where max flow did not go over 10 cfs keep(~ max(as.numeric(.x$Flow)) &gt; 10) %&gt;% map(~select(.x, Date_Time, Depth, Flow)) %&gt;% map(~mutate(.x, time_lag = lag(Date_Time, default = Date_Time[1]), time_lead = lead(Date_Time), diff_time = as.numeric(difftime(time_lead,time_lag, units = &quot;hours&quot;)), diff_depth = lead(Depth) - lag(Depth))) %&gt;% imap(~mutate(.x, event = as.character(.y))) %&gt;% bind_rows() %&gt;% filter(!is.na(diff_depth)) %&gt;% mutate(J = as.numeric(diff_depth)/as.numeric(diff_time)) -&gt; df_16882_2020_12 ## estimate parameters for each dataset ## set parameter starting limits start_lower &lt;- list(K = 0, a = 0, n = 0, x = -5000) start_upper &lt;- list(K = 100, a = 1000, n = 50, x = 5000) rc_16882_2020_03 &lt;- nls_multstart(jones_form, data = df_16882_2020_03, iter = 1000, start_lower = start_lower, start_upper = start_upper, convergence_count = FALSE, supp_errors = &quot;Y&quot;) ## set parameter starting limits start_lower &lt;- list(K = -100, a = 0, n = 0, x = -5000) start_upper &lt;- list(K = 100, a = 1000, n = 50, x = 5000) rc_16882_2020_10 &lt;- nls_multstart(jones_form, data = df_16882_2020_10, iter = 1000, start_lower = start_lower, start_upper = start_upper, convergence_count = FALSE, supp_errors = &quot;Y&quot;) ## set parameter starting limits start_lower &lt;- list(K = 0, a = 0, n = 0, x = -5000) start_upper &lt;- list(K = 100, a = 1000, n = 50, x = 5000) rc_16882_2020_12 &lt;- nls_multstart(jones_form, data = df_16882_2020_12, iter = 1000, start_lower = start_lower, start_upper = start_upper, convergence_count = FALSE, supp_errors = &quot;Y&quot;) ## setup dataframe with parameter results. Will use this later to report parameters and GOF metrics df_results_16882 &lt;- tibble(Site = c(&quot;16882&quot;, &quot;16882&quot;, &quot;16882&quot;), Period = c(&quot;2020-03-01 : 2020-09-30&quot;, &quot;2020-10-01 : 2020-11-30&quot;, &quot;2020-12-01 : 2021-01-31&quot;), K = c(coefficients(rc_16882_2020_03)[[&quot;K&quot;]], coefficients(rc_16882_2020_10)[[&quot;K&quot;]], coefficients(rc_16882_2020_12)[[&quot;K&quot;]]), a = c(coefficients(rc_16882_2020_03)[[&quot;a&quot;]], coefficients(rc_16882_2020_10)[[&quot;a&quot;]], coefficients(rc_16882_2020_12)[[&quot;a&quot;]]), n = c(coefficients(rc_16882_2020_03)[[&quot;n&quot;]], coefficients(rc_16882_2020_10)[[&quot;n&quot;]], coefficients(rc_16882_2020_12)[[&quot;n&quot;]]), x = c(coefficients(rc_16882_2020_03)[[&quot;x&quot;]], coefficients(rc_16882_2020_10)[[&quot;x&quot;]], coefficients(rc_16882_2020_12)[[&quot;x&quot;]])) ## Develop rating curve predictions and ## create table with GOF metrics df_16882_2020_03 %&gt;% filter(!is.na(J)) %&gt;% mutate(predicted = exp(predict(rc_16882_2020_03, data = .))) -&gt; df_16882_2020_03 df_16882_2020_10 %&gt;% filter(!is.na(J)) %&gt;% mutate(predicted = exp(predict(rc_16882_2020_10, data = .))) -&gt; df_16882_2020_10 df_16882_2020_12 %&gt;% filter(!is.na(J)) %&gt;% mutate(predicted = exp(predict(rc_16882_2020_12, data = .))) -&gt; df_16882_2020_12 df_results_16882 %&gt;% mutate(NSE = c( hydroGOF::NSE(df_16882_2020_03$predicted, as.numeric(df_16882_2020_03$Flow)), hydroGOF::NSE(df_16882_2020_10$predicted, as.numeric(df_16882_2020_10$Flow)), hydroGOF::NSE(df_16882_2020_12$predicted, as.numeric(df_16882_2020_12$Flow))), nRMSE = c(hydroGOF::nrmse(df_16882_2020_03$predicted, as.numeric(df_16882_2020_03$Flow), norm = &quot;maxmin&quot;), hydroGOF::nrmse(df_16882_2020_10$predicted, as.numeric(df_16882_2020_10$Flow), norm = &quot;maxmin&quot;), hydroGOF::nrmse(df_16882_2020_12$predicted, as.numeric(df_16882_2020_12$Flow), norm = &quot;maxmin&quot;)) ) -&gt; df_results_16882 ##display table kable(df_results_16882, caption = &quot;Rating curve parameter estimates and goodness-of-fit metrics for station 16882.&quot;) Table 3: Rating curve parameter estimates and goodness-of-fit metrics for station 16882. Site Period K a n x NSE nRMSE 16882 2020-03-01 : 2020-09-30 4.520613 0.9598066 0.1515910 -0.5764236 0.9674766 5.5 16882 2020-10-01 : 2020-11-30 4.429873 0.8771891 0.2634828 -3.6730614 0.9256386 8.0 16882 2020-12-01 : 2021-01-31 3.862130 0.5454953 0.7893605 0.3827598 0.8827666 2.0 ## plot rating curve results p1 &lt;- ggplot(df_16882_2020_03) + geom_point(aes(as.numeric(predicted), as.numeric(Flow), color = &quot;Rating curve prediction against measured flow&quot;), alpha = 0.25) + geom_abline(aes(slope = 1, intercept = 0, linetype = &quot;1:1 line&quot;)) + scale_x_continuous(name = &quot;Rating curve flow estimate [cfs]&quot;, trans = &quot;log10&quot;) + scale_y_continuous(name = &quot;Measured flow [cfs]&quot;, trans = &quot;log10&quot;) + theme_ms() + labs(subtitle = &quot;March-September&quot;) + theme(legend.title = element_blank(), legend.position = &quot;none&quot;) p2 &lt;- ggplot(df_16882_2020_03) + geom_point(aes(as.numeric(Flow), Depth, color = &quot;Measured&quot;)) + geom_path(aes(as.numeric(Flow), Depth, color = &quot;Measured&quot;, linetype = &quot;Measured&quot;), alpha = 0.5) + geom_point(aes(as.numeric(predicted), Depth, color = &quot;Predicted&quot;)) + geom_path(aes(as.numeric(predicted), Depth, color = &quot;Predicted&quot;, linetype = &quot;Predicted&quot;), alpha = 0.5) + scale_color_discrete(&quot;&quot;) + scale_linetype_discrete(&quot;&quot;) + scale_x_continuous(&quot;Flow [cfs]&quot;, trans = &quot;log10&quot;) + labs(subtitle = &quot;March-September&quot;) + theme_ms() + theme(legend.position = &quot;none&quot;) p3 &lt;- ggplot(df_16882_2020_10) + geom_point(aes(as.numeric(predicted), as.numeric(Flow), color = &quot;Rating curve prediction against measured flow&quot;), alpha = 0.25) + geom_abline(aes(slope = 1, intercept = 0, linetype = &quot;1:1 line&quot;)) + scale_x_continuous(name = &quot;Rating curve flow estimate [cfs]&quot;, trans = &quot;log10&quot;) + scale_y_continuous(name = &quot;Measured flow [cfs]&quot;, trans = &quot;log10&quot;) + theme_ms() + labs(subtitle = &quot;October-November&quot;) + theme(legend.title = element_blank(), legend.position = &quot;none&quot;) p4 &lt;- ggplot(df_16882_2020_10) + geom_point(aes(as.numeric(Flow), Depth, color = &quot;Measured&quot;)) + geom_path(aes(as.numeric(Flow), Depth, color = &quot;Measured&quot;, linetype = &quot;Measured&quot;), alpha = 0.5) + geom_point(aes(as.numeric(predicted), Depth, color = &quot;Predicted&quot;)) + geom_path(aes(as.numeric(predicted), Depth, color = &quot;Predicted&quot;, linetype = &quot;Predicted&quot;), alpha = 0.5) + scale_color_discrete(&quot;&quot;) + scale_linetype_discrete(&quot;&quot;) + scale_x_continuous(&quot;Flow [cfs]&quot;, trans = &quot;log10&quot;) + labs(subtitle = &quot;October-November&quot;) + theme_ms() + theme(legend.position = &quot;none&quot;) p5 &lt;- ggplot(df_16882_2020_12) + geom_point(aes(as.numeric(predicted), as.numeric(Flow), color = &quot;Rating curve prediction against measured flow&quot;), alpha = 0.25) + geom_abline(aes(slope = 1, intercept = 0, linetype = &quot;1:1 line&quot;)) + scale_x_continuous(name = &quot;Rating curve flow estimate [cfs]&quot;, trans = &quot;log10&quot;) + scale_y_continuous(name = &quot;Measured flow [cfs]&quot;, trans = &quot;log10&quot;) + theme_ms() + labs(subtitle = &quot;December-January&quot;) + theme(legend.title = element_blank()) p6 &lt;- ggplot(df_16882_2020_12) + geom_point(aes(as.numeric(Flow), Depth, color = &quot;Measured&quot;)) + geom_path(aes(as.numeric(Flow), Depth, color = &quot;Measured&quot;, linetype = &quot;Measured&quot;), alpha = 0.5) + geom_point(aes(as.numeric(predicted), Depth, color = &quot;Predicted&quot;)) + geom_path(aes(as.numeric(predicted), Depth, color = &quot;Predicted&quot;, linetype = &quot;Predicted&quot;), alpha = 0.5) + scale_color_discrete(&quot;&quot;) + scale_linetype_discrete(&quot;&quot;) + scale_x_continuous(&quot;Flow [cfs]&quot;, trans = &quot;log10&quot;) + labs(subtitle = &quot;December-January&quot;) + theme_ms() (p1 + p2) / (p3 + p4) / (p5 + p6) + plot_annotation(tag_levels = &quot;A&quot;) Figure 4: Scatter plot of rating curve estimated flows against measured flows (A, C, E) and stage discharge predictions (B, D, F) for each rating curve period at station 16882. "]]
