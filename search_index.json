[["index.html", "Exploring Thompsons Creek Stage Discharge Data About Data Import Data Explore IQPlus", " Exploring Thompsons Creek Stage Discharge Data 2021-02-04 About This document is an exploratory analysis of the pressure data and IQ data at … library(readr) library(tibble) library(dplyr) library(ggplot2) library(stringr) library(here) library(units) library(ggforce) library(hrbrthemes) library(lubridate) update_geom_font_defaults(font_rc) theme_ms &lt;- function(...) { theme_ipsum_pub(plot_margin = margin(10,10,10,10), axis_title_just = &quot;c&quot;) + theme(legend.position = &quot;bottom&quot;, panel.background = element_rect(fill = &quot;white&quot;, colour = NA), panel.border = element_rect(fill = NA, colour = &quot;grey20&quot;), ...) } Data Import Pressure Transducers Use readr::read_csv() to import data. The HOBO pressure data is pre-computed but has extra lines we need to clean up. each location has two files, March through August and August through December. ideally, I can make one dataframe that compiles all the data we can read all the files and row bind but we need to add a column indicating the site number for this deployment it looks like the daylight savings time adjustment is not applied to data. So everything between March 6 and November 1 is off 1 hour from DST. Assuming all data will be reported in observed time, it is probably easiest to convert time back to GMT, then apply R’s built in time zones to convert the times with appropriate -5 or -6 hour offsets. ## make a list of files to import file_paths &lt;- paste0(here(&quot;Data/Hobo&quot;), &quot;/&quot;, list.files(path = here(&quot;Data/Hobo&quot;), pattern = &quot;.csv&quot;)) ## create a blank tibble to fill hobo_df &lt;- tibble() ## loop through file paths to read each file for (i in file_paths) { x &lt;- read_csv( i, skip = 2, col_names = c( &quot;Row&quot;, &quot;Date&quot;, &quot;Time&quot;, &quot;Abs_Pres&quot;, &quot;Temp&quot;, &quot;Bar_Pressure&quot;, &quot;Water_Level&quot;, &quot;Coupler_Detached&quot;, &quot;Coupler_Attached&quot;, &quot;Stopped&quot;, &quot;EOF&quot; ), col_types = &quot;nccnnnncccc&quot; ) x$file &lt;- i hobo_df &lt;- bind_rows(hobo_df, x) rm(x) } ## clean up the dataframe hobo_df &lt;- hobo_df %&gt;% mutate( ## regex extracts site number from file path Site = str_extract(file, &quot;\\\\d{1,6}&quot;), ## convert date and time columns to date/time format dt = paste(Date, Time), Date_Time = as.POSIXct(paste(Date, Time), tz = &quot;Etc/GMT-6&quot;, format = &quot;%m/%d/%y %I:%M:%S %p&quot;)) %&gt;% mutate(Site = as.factor(Site)) %&gt;% ## select the columns we need to keep dplyr::select(Abs_Pres, Temp, Water_Level, Site, Date_Time) %&gt;% ## filter rows without water_level dplyr::filter(!is.na(Water_Level)) ## attach units to our columns units(hobo_df$Water_Level) &lt;- as_units(&quot;ft&quot;) units(hobo_df$Temp) &lt;- as_units(&quot;°F&quot;) units(hobo_df$Abs_Pres) &lt;- as_units(&quot;psi&quot;) hobo_df ## # A tibble: 71,447 x 5 ## Abs_Pres Temp Water_Level Site Date_Time ## [psi] [°F] [ft] &lt;fct&gt; &lt;dttm&gt; ## 1 14.4270 76.006 0.392 16396 2020-03-02 15:17:19 ## 2 14.4237 75.659 0.388 16396 2020-03-02 15:32:19 ## 3 14.4272 75.312 0.399 16396 2020-03-02 15:47:19 ## 4 14.4192 74.964 0.391 16396 2020-03-02 16:02:19 ## 5 14.4165 74.791 0.379 16396 2020-03-02 16:17:19 ## 6 14.4153 74.446 0.361 16396 2020-03-02 16:32:19 ## 7 14.4172 74.271 0.364 16396 2020-03-02 16:47:19 ## 8 14.4166 74.098 0.363 16396 2020-03-02 17:02:19 ## 9 14.4207 73.926 0.372 16396 2020-03-02 17:17:19 ## 10 14.4270 73.753 0.376 16396 2020-03-02 17:32:19 ## # … with 71,437 more rows IQ Plus #read_csv(here::here(&quot;Data/IQPlus/16397-2020_12_31.csv&quot;)) ## make a list of files to import file_paths &lt;- paste0(here(&quot;Data/IQPlus&quot;), &quot;/&quot;, list.files(path = here(&quot;Data/IQPlus&quot;), pattern = &quot;.csv&quot;)) ## create a blank tibble to fill iqplus_df &lt;- tibble() ## loop through file paths to read each file for (i in file_paths) { x &lt;- read_csv( i, col_types = &quot;nc______n__n______________________nn______n_________&quot; ) x$file &lt;- i iqplus_df &lt;- bind_rows(iqplus_df, x) rm(x) } iqplus_df &lt;- iqplus_df %&gt;% mutate( ## regex extracts site number from file path Site = str_extract(file, &quot;\\\\d{1,6}&quot;)) %&gt;% ## use `dplyr::` to specify which rename function to use, just in case dplyr::rename(Sample_Number =`Sample number`, Date_Time = `Sample time`, Depth = `Depth (ft)`, Flow = `Flow (ft³/s)`, System_In_Water = `System in water (%)`, System_Status = `System status (status codes)`, Index_Velocity = `Velocity (mean) (ft/s)`) %&gt;% dplyr::select(-c(Sample_Number, file)) %&gt;% mutate(Date_Time = as.POSIXct(Date_Time, tz = &quot;Etc/GMT-6&quot;, format = &quot;%Y-%m-%d %H:%M:%S&quot;)) ## attach units to our columns units(iqplus_df$Depth) &lt;- as_units(&quot;ft&quot;) units(iqplus_df$Flow) &lt;- as_units(&quot;ft^3/s&quot;) units(iqplus_df$Index_Velocity) &lt;- as_units(&quot;ft/s&quot;) iqplus_df ## # A tibble: 41,625 x 7 ## Date_Time Depth Flow System_In_Water System_Status ## &lt;dttm&gt; [ft] [ft^3/s] &lt;dbl&gt; &lt;dbl&gt; ## 1 2020-05-12 16:58:00 1.758559 17.25626 100 0 ## 2 2020-05-12 17:13:00 1.867973 20.86921 100 0 ## 3 2020-05-12 17:28:00 2.006131 27.27231 100 0 ## 4 2020-05-12 17:43:00 2.119382 31.04828 100 0 ## 5 2020-05-12 17:58:00 2.172015 33.71041 100 0 ## 6 2020-05-12 18:13:00 2.228058 36.78339 100 0 ## 7 2020-05-12 18:28:00 2.350440 44.18084 100 0 ## 8 2020-05-12 18:43:00 2.508431 51.30917 100 0 ## 9 2020-05-12 18:58:00 2.674151 60.84247 100 0 ## 10 2020-05-12 19:13:00 2.809936 69.92496 100 0 ## # … with 41,615 more rows, and 2 more variables: Index_Velocity [ft/s], ## # Site &lt;chr&gt; Data Explore Pressure Transducers Plot the depth date over time for all three sites ## note, that if the scale name has a space, there is a bug in ggforce ## need to set units_options(parse = FALSE) per: ## https://github.com/thomasp85/ggforce/issues/197 ggplot(hobo_df) + geom_line(aes(Date_Time, Water_Level, color = Site)) + scale_y_unit(name = &quot;Level&quot;, unit = &quot;ft&quot;) + scale_x_datetime(name = &quot;Date/Time&quot;) + labs(title = &quot;15-Minute Measured Height&quot;) + theme_ms() IQPlus Plot the depth data drom the IQPlus from all three sites. iqplus_df %&gt;% filter(System_Status == 0, System_In_Water == 100) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth, color = Site)) + facet_wrap(~Site, scales = &quot;free&quot;) + labs(title = &quot;Stage&quot;) + theme_ms() Plot the depth-discharge from all three sites as measured by the IQPlus. iqplus_df %&gt;% filter(System_Status == 0, System_In_Water == 100, as.numeric(Flow) &gt; 0) %&gt;% ggplot() + geom_point(aes(Depth, Flow, color = Site)) + scale_y_unit(name = &quot;Flow&quot;, unit = &quot;ft^3/s&quot;) + facet_wrap(~Site, scales = &quot;free&quot;) + labs(title = &quot;Stage Discharge&quot;) + theme_ms() iqplus_df %&gt;% filter(System_Status == 0, System_In_Water == 100) %&gt;% mutate(Month = lubridate::month(Date_Time, label = TRUE)) %&gt;% ggplot() + geom_point(aes(Depth, Flow, color = Month), alpha = 0.5) + scale_y_unit(name = &quot;Flow&quot;, unit = &quot;ft^3/s&quot;) + facet_wrap(~Site, scales = &quot;free&quot;) + labs(title = &quot;Stage Discharge&quot;) + theme_ms() Site 16396 looks pretty good. We still have some data cleaning and sorting on the remaining two sites. Exploring 16397 further… iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, #as.numeric(Depth) &gt;= 0.75, as.numeric(Flow) &gt; 0) %&gt;% mutate(Month = lubridate::month(Date_Time, label = TRUE)) %&gt;% ggplot() + geom_point(aes(Depth, Flow, color = Month), alpha = 0.5) + scale_y_unit(name = &quot;Flow&quot;, unit = &quot;ft^3/s&quot;) + facet_wrap(~Month) + labs(title = &quot;Stage Discharge&quot;) + theme_ms() + theme(panel.spacing = unit(2, &quot;points&quot;)) Exploring 16882 further… iqplus_df %&gt;% filter(Site == &quot;16882&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Flow) &gt; 0) %&gt;% mutate(Month = lubridate::month(Date_Time, label = TRUE)) %&gt;% ggplot() + geom_point(aes(Depth, Flow, color = Month), alpha = 0.5) + scale_y_unit(name = &quot;Flow&quot;, unit = &quot;ft^3/s&quot;) + facet_wrap(~Month) + labs(title = &quot;Stage Discharge&quot;) + theme_ms() + theme(panel.spacing = unit(2, &quot;points&quot;)) The looped rating curve in May and Dec might be a flood flow event. Discharge is typically higher on the rising stage than the falling stage. iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &lt;= as.POSIXct(&quot;2020-07-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &lt;= as.POSIXct(&quot;2020-07-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &lt;= as.POSIXct(&quot;2020-07-01&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-07-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-09-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-07-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-09-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-07-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-09-01&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-09-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-10-15&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-09-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-10-15&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-09-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-10-15&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-10-15&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-11-25&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-10-15&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-11-25&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-10-15&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-11-25&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-11-25&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-15&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-11-25&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-15&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-11-25&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-15&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-12-15&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-12-15&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt; 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-12-15&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, #System_Status == 0, #System_In_Water == 100, #as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, #System_Status == 0, #System_In_Water == 100, #as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16397&quot;, #System_Status == 0, #System_In_Water == 100, #as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow)) ##16396 iqplus_df %&gt;% filter(Site == &quot;16396&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-12-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16396&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-12-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16396&quot;, System_Status == 0, System_In_Water == 100, as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2020-12-01&quot;) &amp; Date_Time &lt; as.POSIXct(&quot;2020-12-31&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow, color = Date_Time)) + scale_y_unit(trans = &quot;log10&quot;) iqplus_df %&gt;% filter(Site == &quot;16396&quot;, #System_Status == 0, #System_In_Water == 100, #as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Flow)) iqplus_df %&gt;% filter(Site == &quot;16396&quot;, #System_Status == 0, #System_In_Water == 100, #as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) %&gt;% ggplot() + geom_point(aes(Date_Time, Depth)) iqplus_df %&gt;% filter(Site == &quot;16396&quot;, #System_Status == 0, #System_In_Water == 100, #as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) %&gt;% ggplot() + geom_point(aes(Depth, Flow, color = Date_Time)) Can we model this hysteresis? Zakwan 2018: \\[ Q = K(h-a)^n\\times\\sqrt{1 + x\\frac{\\partial h}{\\partial t}} \\] \\(Q\\) is discharge \\(h\\) is gage height \\(\\frac{\\partial h}{\\partial t}}\\) is the derivative of gage height with respect to time. Solve for K, a, n, x by minimizing sum of square error (SSE). \\[ SSE = \\sum\\limits_{i=1}^N[X-Y]^2 \\] iqplus_df %&gt;% filter(Site == &quot;16396&quot;, #System_Status == 0, #System_In_Water == 100, #as.numeric(Depth) &gt;= 0.26, ## minimum operating depth as.numeric(Flow) &gt;= 0) %&gt;% filter(Date_Time &gt; as.POSIXct(&quot;2021-01-01&quot;)) -&gt; df_16396 NLL &lt;- function(pars, data) { Depth = as.numeric(data$Depth) fDepth = diff(Depth) #print(paste(&quot;fd=&quot;,fDepth[1])) Time = as.numeric(data$Date_Time) fTime = diff(Time) #print(paste(&quot;ft=&quot;, fTime[1])) Depth = Depth[2:length(Depth)] #print(paste(&quot;H=&quot;,Depth[1])) K = pars[1] a = pars[2] n = pars[3] x = pars[4] preds &lt;- (K*(Depth - a)^n) * sqrt(1 + x * (fDepth/fTime)) #print(preds[1:5]) Q = as.numeric(data$Flow) Q = Q[2:length(Q)] ## minimize the sum of square errors per the paper sse &lt;- sum((Q - preds)^2) #print(sse) sse } par &lt;- c(K = 1, a = .5, n = 2, x = 2000) ## limits to the parameter space lower &lt;- c(-10, -10, -10, 0.1) upper &lt;- c(200, 500, 10, 5000) optim.par &lt;- optim(par = par, fn = NLL, data = df_16396, lower = lower, upper = upper, method = &quot;L-BFGS-B&quot;) K &lt;- optim.par$par[1] a &lt;- optim.par$par[2] n &lt;- optim.par$par[3] x &lt;- optim.par$par[4] df_16396 %&gt;% mutate(predicted = (K*(as.numeric(Depth) - a)^n) * sqrt(1 + x * (c(NA, diff(as.numeric(Depth)))/c(NA,diff(as.numeric(Date_Time)))))) %&gt;% ggplot() + geom_point(aes(as.numeric(Depth), as.numeric(Flow), color = &quot;measured&quot;), alpha = 0.5) + geom_point(aes(as.numeric(Depth), as.numeric(predicted), color = &quot;predicted&quot;), alpha = 0.2) + scale_y_log10() ## Warning: Removed 1 rows containing missing values (geom_point). df_16396 %&gt;% mutate(predicted = (K*(as.numeric(Depth) - a)^n) * sqrt(1 + x * (c(NA, diff(as.numeric(Depth)))/c(NA,diff(as.numeric(Date_Time)))))) %&gt;% ggplot() + geom_point(aes(predicted, as.numeric(Flow)), color = &quot;dodgerblue&quot;, alpha = 0.5) + scale_x_log10() + scale_y_log10() ## Warning: Removed 1 rows containing missing values (geom_point). So this appears to fit pretty well. In order to incorporate the first derivative function of stream height we will need to (1) split the data set into each sampling period; (2) calculate the derivatives in each dataset; (3) remove rows with NA (basically first record in each sampling event); (4) combine desired datasets based on shape or sample the datasets; (4) refit the function above to one or more datasets. Can probably split datasets and use purrr to do this? To do: [] visually compare measured depths with the IQ and the Hobos [] need to better understand the remaining columns in the IQPlus dataset to see if we can systematically clean the data [] do we need to group measurement events? ie. should the rating curve be built from certain portions of the hydrograph (need to see what the literature says) "]]
